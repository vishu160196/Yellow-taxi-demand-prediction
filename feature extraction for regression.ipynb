{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'cluster-wise-dfs.pickle',\n",
       " 'df-new-features.pickle',\n",
       " 'exp-wa-past-values-dfs.pickle',\n",
       " 'exp-wa-past-values-week-days-dfs.pickle',\n",
       " 'feature extraction for regression.ipynb',\n",
       " 'feb-2016-groupby.csv',\n",
       " 'feb-2016-outliers-removed.csv',\n",
       " 'feb-2016-smooth.pickle',\n",
       " 'jan-2016-groupby.csv',\n",
       " 'jan-2016-outliers-removed.csv',\n",
       " 'jan-2016-smooth.pickle',\n",
       " 'mar-2016-groupby.csv',\n",
       " 'mar-2016-outliers-removed.csv',\n",
       " 'mar-2016-smooth.pickle',\n",
       " 'march-2016-groupby.csv',\n",
       " 'march-2016-outliers-removed.csv',\n",
       " 'mydask.png',\n",
       " 'NYC Final.ipynb',\n",
       " 'Regression models.ipynb',\n",
       " 'rf-fi.pickle']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('jan-2016-smooth.pickle', 'rb') as f:\n",
    "    jan_2016_smooth=pickle.load(f)\n",
    "    \n",
    "with open('feb-2016-smooth.pickle', 'rb') as f:\n",
    "    feb_2016_smooth=pickle.load(f)\n",
    "    \n",
    "with open('mar-2016-smooth.pickle', 'rb') as f:\n",
    "    mar_2016_smooth=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(jan_2016_smooth)==40*(24*31*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4464"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(24*31*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EA_P1_Predictions(ratios, alpha):\n",
    "    predicted_value= (ratios['Prediction'].values)[0]*alpha \n",
    "    error=[]\n",
    "    predicted_values=[]\n",
    "    \n",
    "    for i in range(0,13104*40):\n",
    "        if i%13104==0:\n",
    "            predicted_values.append(0)\n",
    "            error.append(0)\n",
    "            continue\n",
    "        predicted_values.append(predicted_value)\n",
    "        error.append(abs((math.pow(predicted_value-(ratios['Prediction'].values)[i],1))))\n",
    "        predicted_value =int((alpha*predicted_value) + (1-alpha)*((ratios['Prediction'].values)[i]))\n",
    "    \n",
    "    ratios['EA_P1_Predicted'] = predicted_values\n",
    "    ratios['EA_P1_Error'] = error\n",
    "    mape_err = (sum(error)/len(error))/(sum(ratios['Prediction'].values)/len(ratios['Prediction'].values))\n",
    "    mse_err = sum([e**2 for e in error])/len(error)\n",
    "    return ratios,mape_err,mse_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine time series of 3 months to generate one time series spread over 3 months for each of 40 regions\n",
    "\n",
    "jan_bins=31*24*6\n",
    "feb_bins=29*24*6\n",
    "mar_bins=31*24*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions=[]\n",
    "for r in range(40):\n",
    "    regions.append(jan_2016_smooth[r*jan_bins:(r+1)*jan_bins]+feb_2016_smooth[r*feb_bins:(r+1)*feb_bins]+\n",
    "                   mar_2016_smooth[r*mar_bins:(r+1)*mar_bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bins=jan_bins+feb_bins+mar_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# jan_bins+feb_bins+mar_bins==13104\n",
    "import numpy as np\n",
    "np.all(np.array([len(r) for r in regions])==total_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_pickups=[]\n",
    "for r in regions:\n",
    "    combined_pickups.extend(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios=pd.DataFrame()\n",
    "ratios['Prediction']=combined_pickups\n",
    "ratios, mape_err, mse_err=EA_P1_Predictions(ratios, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13191766220001513"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_err # error reduces as data increases. Using only jan 2016 data gives 13.5% error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# region wise division of dataframes\n",
    "regions_df=[]\n",
    "for r in range(40):\n",
    "    regions_df.append(ratios[r*total_bins:(r+1)*total_bins])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>EA_P1_Predicted</th>\n",
       "      <th>EA_P1_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>217</td>\n",
       "      <td>44.0</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>189</td>\n",
       "      <td>165.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>137</td>\n",
       "      <td>181.0</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  EA_P1_Predicted  EA_P1_Error\n",
       "0           0              0.0          0.0\n",
       "1          63              0.0         63.0\n",
       "2         217             44.0        173.0\n",
       "3         189            165.0         24.0\n",
       "4         137            181.0         44.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].head() # 3 month time series prediction for region 0 using exponential weighted averages of past values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>EA_P1_Predicted</th>\n",
       "      <th>EA_P1_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13104</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13105</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13106</th>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13107</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13108</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  EA_P1_Predicted  EA_P1_Error\n",
       "13104           0              0.0          0.0\n",
       "13105           0             45.0         45.0\n",
       "13106           1             13.0         12.0\n",
       "13107           0              4.0          4.0\n",
       "13108           3              1.0          2.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[1].head() # 3 month time series prediction for region 1 using exponential weighted averages of past values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>EA_P1_Predicted</th>\n",
       "      <th>EA_P1_Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26209</th>\n",
       "      <td>119</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26210</th>\n",
       "      <td>181</td>\n",
       "      <td>83.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26211</th>\n",
       "      <td>180</td>\n",
       "      <td>151.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26212</th>\n",
       "      <td>186</td>\n",
       "      <td>171.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  EA_P1_Predicted  EA_P1_Error\n",
       "26208           0              0.0          0.0\n",
       "26209         119              0.0        119.0\n",
       "26210         181             83.0         98.0\n",
       "26211         180            151.0         29.0\n",
       "26212         186            171.0         15.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[2].head() # 3 month time series prediction for region 2 using exponential weighted averages of past values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp-wa-past-values-dfs.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp-wa-past-values-dfs.pickle', 'rb') as f:\n",
    "    regions_df=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mape(predictions, truth):\n",
    "    return 100*np.sum(np.abs(predictions-truth))/np.sum(truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "jan_df=pd.read_csv('jan-2016-outliers-removed.csv')\n",
    "feb_df=pd.read_csv('feb-2016-outliers-removed.csv')\n",
    "mar_df=pd.read_csv('march-2016-outliers-removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate 40 dataframes, one for each cluster\n",
    "regions_df_full=[]\n",
    "\n",
    "for r in range(40):\n",
    "    regions_df_full.append(pd.concat((jan_df[jan_df['pickup_cluster']==r].sort_values(by='pickup_bins'), \n",
    "                                      feb_df[feb_df['pickup_cluster']==r].sort_values(by='pickup_bins'),\n",
    "                                     mar_df[mar_df['pickup_cluster']==r].sort_values(by='pickup_bins'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cluster-wise-dfs.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_df_full, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One hot encoding of days of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_day=[]\n",
    "for r in range(40):\n",
    "    week_day.append([int(((int(k/144))%7+4)%7) for k in range(total_bins)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in range(40):\n",
    "    regions_df[r]['week_day']=week_day[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp-wa-past-values-week-days-dfs.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('exp-wa-past-values-week-days-dfs.pickle', 'rb') as f:\n",
    "    regions_df=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(df, col):\n",
    "    enc = OneHotEncoder(categories='auto')\n",
    "    enc.fit(np.array([df[col].values]).T)\n",
    "    \n",
    "    col_one_hot_encoded=np.array(enc.transform(np.array([df[col].values]).T).todense())\n",
    "#     df.drop(col, axis=1, inplace=True)\n",
    "    \n",
    "    for i, category in enumerate(enc.categories_[0]):\n",
    "        df[str(category)]=col_one_hot_encoded[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    one_hot_encode(df, 'week_day')\n",
    "    df.drop('week_day', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[1].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[-1].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickup bin value 1 week earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13104"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(regions_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of rows lost = 1008, remaining rows = 12096\n"
     ]
    }
   ],
   "source": [
    "print(f'no of rows lost = {7*24*6}, remaining rows = {13104-7*24*6}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    df['last_week_pred']=df['Prediction'].shift(7*24*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction         40.0\n",
       "EA_P1_Predicted    52.0\n",
       "EA_P1_Error        12.0\n",
       "0                   0.0\n",
       "1                   0.0\n",
       "2                   0.0\n",
       "3                   0.0\n",
       "4                   1.0\n",
       "5                   0.0\n",
       "6                   0.0\n",
       "last_week_pred      0.0\n",
       "Name: 1008, dtype: float64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].iloc[7*24*6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickup bin value 1 day earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    df['previous_day_pred']=df['Prediction'].shift(24*6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Last 5 pickup bin values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    for prev in range(1,6):\n",
    "        df['p_'+str(prev)]=df['Prediction'].shift(prev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred', 'p_1', 'p_2', 'p_3',\n",
       "       'p_4', 'p_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Max of last 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    df['max_last_5']=df[['p_1', 'p_2', 'p_3', 'p_4', 'p_5']].apply(max, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred', 'p_1', 'p_2', 'p_3',\n",
       "       'p_4', 'p_5', 'max_last_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min of last 5 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    df['min_last_5']=df[['p_1', 'p_2', 'p_3', 'p_4', 'p_5']].apply(min, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred', 'p_1', 'p_2', 'p_3',\n",
       "       'p_4', 'p_5', 'max_last_5', 'min_last_5'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Std dev of last 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_dev(numbers):\n",
    "    return np.var(numbers)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    col_names=['p_'+str(i) for i in range(1,11)]\n",
    "    for shift in range(6, 11):\n",
    "        df['p_'+str(shift)]=df['Prediction'].shift(shift)\n",
    "        \n",
    "    df['std_dev_10']=df[col_names].apply(std_dev, axis=1)\n",
    "    \n",
    "    for shift in range(6, 11):\n",
    "        df.drop('p_'+str(shift), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred', 'p_1', 'p_2', 'p_3',\n",
       "       'p_4', 'p_5', 'max_last_5', 'min_last_5', 'std_dev_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction           131.00000\n",
       "EA_P1_Predicted      153.00000\n",
       "EA_P1_Error           22.00000\n",
       "0                      0.00000\n",
       "1                      0.00000\n",
       "2                      0.00000\n",
       "3                      0.00000\n",
       "4                      1.00000\n",
       "5                      0.00000\n",
       "6                      0.00000\n",
       "last_week_pred             NaN\n",
       "previous_day_pred          NaN\n",
       "p_1                  152.00000\n",
       "p_2                  164.00000\n",
       "p_3                  150.00000\n",
       "p_4                  129.00000\n",
       "p_5                  135.00000\n",
       "max_last_5           164.00000\n",
       "min_last_5           129.00000\n",
       "std_dev_10            58.67231\n",
       "Name: 10, dtype: float64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].iloc[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DFT of last 2 hour values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(series):\n",
    "    return np.abs(np.fft.fft(series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    col_names=['p_'+str(i) for i in range(1,13)]\n",
    "    for shift in range(6, 13):\n",
    "        df['p_'+str(shift)]=df['Prediction'].shift(shift)\n",
    "        \n",
    "    dft_series=df[col_names].apply(dft, axis=1).values\n",
    "    \n",
    "    for shift in range(1, 13):\n",
    "        component=[]\n",
    "        for arr in dft_series:\n",
    "            component.append(arr[shift-1])\n",
    "        \n",
    "        df['component_'+str(shift)]=component\n",
    "        \n",
    "        if shift>=6:\n",
    "            df.drop('p_'+str(shift), axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Prediction', 'EA_P1_Predicted', 'EA_P1_Error', '0', '1', '2', '3', '4',\n",
       "       '5', '6', 'last_week_pred', 'previous_day_pred', 'p_1', 'p_2', 'p_3',\n",
       "       'p_4', 'p_5', 'max_last_5', 'min_last_5', 'std_dev_10', 'component_1',\n",
       "       'component_2', 'component_3', 'component_4', 'component_5',\n",
       "       'component_6', 'component_7', 'component_8', 'component_9',\n",
       "       'component_10', 'component_11', 'component_12'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('nans-included-all-features.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in regions_df:\n",
    "    df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12096"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(regions_df[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('df-new-features.pickle', 'wb') as f:\n",
    "    pickle.dump(regions_df, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
